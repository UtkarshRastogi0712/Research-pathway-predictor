{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Rake and stopwords\n",
    "import RAKE\n",
    "import operator\n",
    "stop_dir = \"stop_words.txt\"\n",
    "rake_object = RAKE.Rake(stop_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting keywords found based on scores\n",
    "def Sort_Tuple(tup):\n",
    "    tup.sort(key=lambda x:x[1])\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"How does Keyphrase Extraction work?\n",
    "Lemmatize Text: It doesn’t make sense to include each and every word in the vocabulary of the text passage when words like writing’, ‘written’, ‘wrote’ as they mean the same: ‘write’. So, we lemmatize text, i.e., bring each word to its root form before anything else.\n",
    "Select Potential Phrases: Text passages contain many words, but not all of them are relevant. Most of them might be frequently used words like ‘a’, ‘that’, ‘then’ and so on. Such words, called stopwords, must be filtered else they will contaminate the output. Consecutive words bearing contextual similarity must be grouped together.\n",
    "Score Each Phrase: Once you have a list of possible phrases, you need to rank them to figure out which one is the most important.\" #text should be here in string format\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords=Sort_Tuple(rake_object.run(text)) #keywords - list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [i[0] for i in keywords]\n",
    "keys = keys[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression\n",
      "SVD\n",
      "Text processing using NLTK, spaCy\n",
      "https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a\n",
      "Computational linguistics and word vectors\n",
      "Project - Sentiment detection model using word embeddings\n",
      "RNNs for text classification \n",
      "https://dennybritz.com/posts/wildml/understanding-convolutional-neural-networks-for-nlp/\n",
      "sequential modeling\n",
      "Transfer learning \n",
      "ULMFit by FastAi\n",
      "Project - Using bert and gpt-2 finetuning\n",
      "chatbots and audio processing\n"
     ]
    }
   ],
   "source": [
    "nlp = [\"nlp\", \"tokenization\", \"token\", \"stemming\", \"corpus\", \"stop words\", \"words\", \"text\", \"pos\", \"speech\", \"tag\", \"ngrams\", \"sentiment\", \"nltk\", \"language\"]\n",
    "cv = [\"vision\", \"image\", \"face\", \"augmentation\", \"pixels\", \"rgb\", \"colors\", \"ocr\", \"motion\", \"camera\", \"jpeg\", \"png\", \"tensorflow\", \"pytorch\", \"convolution\", \"cnn\", \"gans\"]\n",
    "be = [\"api\", \"flask\", \"aws\", \"deploy\", \"host\", \"database\", \"django\"]\n",
    "fe = [\"html\", \"css\", \"js\", \"react\", \"ui\", \"interface\", \"server\", \"client\", \"post\", \"get\"]\n",
    "blockchain = [\"encryption\", \"crypto\", \"mining\", \"token\", \"nodes\", \"hash\", \"nonce\"]\n",
    "prime = 0\n",
    "for i in keys:\n",
    "    if i in nlp:\n",
    "        print(\"\"\"Regression\n",
    "SVD\n",
    "Text processing using NLTK, spaCy\n",
    "https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a\n",
    "Computational linguistics and word vectors\n",
    "Project - Sentiment detection model using word embeddings\n",
    "RNNs for text classification \n",
    "https://dennybritz.com/posts/wildml/understanding-convolutional-neural-networks-for-nlp/\n",
    "sequential modeling\n",
    "Transfer learning \n",
    "ULMFit by FastAi\n",
    "Project - Using bert and gpt-2 finetuning\n",
    "chatbots and audio processing\"\"\")\n",
    "        prime = 1\n",
    "        break\n",
    "    elif i in cv:\n",
    "        print(\"\"\"Deep Learning - https://www.coursera.org/learn/neural-networks-deep-learning\n",
    "Handwritten Digits Classifier - \n",
    "Object Localization(Find Waldo using OpenCV) - \n",
    "Recognize digits in a Sudoku picture and solve it - \n",
    "Face Recognition and FaceNet - \n",
    "Deploy a model on AWS Sagemaker/Heroku\n",
    "\"\"\")\n",
    "        prime = 1\n",
    "        break\n",
    "    elif i in be:\n",
    "        print(\"\"\"Learn Python/Javascript\n",
    "Learn Flask/Django/Nodejs\n",
    "Integrate Flask in a simple Web Application\n",
    "Integrate Flask with tensorflow h5 Files and AI models\n",
    "Store data in SQL/MongoDB\n",
    "Store data from a webapp into AWS S3\n",
    "Deploy a model on AWS SageMaker\"\"\")\n",
    "        break\n",
    "        prime = 1\n",
    "    elif i in fe:\n",
    "        print(\"\"\"Learn Python/Javascript\n",
    "Learn Flask/Django/Nodejs\n",
    "Integrate Flask in a simple Web Application\n",
    "Integrate Flask with tensorflow h5 Files and AI models\n",
    "Store data in SQL/MongoDB\n",
    "Store data from a webapp into AWS S3\n",
    "Deploy a model on AWS SageMaker\"\"\")\n",
    "        prime = 1\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "if prime == 0:\n",
    "    print(\"No pathways available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
